{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Sublimation Enthalpy_CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some necessary modules are loaded\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import WhiteKernel, RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 145)\n"
     ]
    }
   ],
   "source": [
    "# Reading data from the data file\n",
    "df   = pd.read_csv('fp_cv.csv', delimiter=',', header=0)\n",
    "data_nonan = np.array(df)\n",
    "\n",
    "\n",
    "# X (fingerprint) and Y (property) of the polymers \n",
    "X_nonan = data_nonan[:,1:]\n",
    "Y = data_nonan[:,0]\n",
    "\n",
    "#Standardization MinMaxScaler \n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X = min_max_scaler.fit_transform(X_nonan)\n",
    "\n",
    "print (np.shape(data_nonan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (269, 144)\n",
      "X_test (30, 144)\n",
      "Y_train (269,)\n",
      "Y_test (30,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and test sets\n",
    "test_size = 0.1\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = test_size, random_state=1)\n",
    "print (\"X_train\",np.shape(X_train))\n",
    "print (\"X_test\",np.shape(X_test))\n",
    "print (\"Y_train\",np.shape(Y_train))\n",
    "print (\"Y_test\",np.shape(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ncv, rmse_train, rmse_test:  0 8.889007226369564 16.27824570499385\n",
      "        ncv, rmse_train, rmse_test:  1 9.601809948574594 12.276374494962663\n",
      "        ncv, rmse_train, rmse_test:  2 9.460692243106418 18.53599211784204\n",
      "        ncv, rmse_train, rmse_test:  3 7.207371608980688 20.995707038654025\n",
      "        ncv, rmse_train, rmse_test:  4 10.602249966906736 17.31962807697584\n",
      "        Optimal ncv:  1 ; optimal kernel saved.\n"
     ]
    }
   ],
   "source": [
    "# Some initial parameters to determine the hyperparameters \n",
    "Y_average = np.average(Y)\n",
    "noise_avr = np.std(Y)\n",
    "noise_lb  = noise_avr/10\n",
    "noise_ub  = noise_avr*10\n",
    "n_fold    = 5\n",
    "\n",
    "# The prior of the GPR model\n",
    "kernel   = (Y_average)**2*RBF(length_scale=1)+WhiteKernel(noise_level=noise_avr**2,noise_level_bounds=(noise_lb**2, noise_ub**2))\n",
    "#gp       = GaussianProcessRegressor(kernel=kernel, alpha=0, n_restarts_optimizer=5)\n",
    "\n",
    "# Now training the GPR model\n",
    "#opt_gp   = gp\n",
    "opt_rmse = 1.0E20\n",
    "ncv      = 0\n",
    "ncv_opt  = ncv\n",
    "\n",
    "# Training set splitted into n_fold subsets\n",
    "kf_      = KFold(n_splits=n_fold, shuffle = True)\n",
    "kf       = kf_.split(X_train)\n",
    "\n",
    "##print (kf_.get_n_splits(kf))\n",
    "# Loop for the best kernal\n",
    "for train, test in kf:\n",
    "    ##print (train.shape)\n",
    "    ##print (test.shape)\n",
    "    X_cv_train = X_train[train]\n",
    "    X_cv_test  = X_train[test]\n",
    "    Y_cv_train = Y_train[train]\n",
    "    Y_cv_test  = Y_train[test]\n",
    "    \n",
    "    gp         = GaussianProcessRegressor(kernel=kernel, alpha=0, n_restarts_optimizer=10)\n",
    "    gp.fit(X_cv_train, Y_cv_train)\n",
    "    y_cv_train = gp.predict(X_cv_train, return_std=False) \n",
    "    y_cv_test  = gp.predict(X_cv_test, return_std=False)  \n",
    "\n",
    "    rmse_cv_train = np.sqrt(mean_squared_error(Y_cv_train, y_cv_train))\n",
    "    rmse_cv_test  = np.sqrt(mean_squared_error(Y_cv_test, y_cv_test))\n",
    "    print('        ncv, rmse_train, rmse_test: ', ncv, rmse_cv_train, rmse_cv_test)\n",
    "\n",
    "    if rmse_cv_test < opt_rmse:\n",
    "        opt_rmse = rmse_cv_test\n",
    "        opt_gp   = gp #如果有满足条件的优化，就选优化后的kernal，否则还使用原始的gp\n",
    "        ncv_opt  = ncv\n",
    "\n",
    "    ncv = ncv + 1\n",
    "\n",
    "print('        Optimal ncv: ', ncv_opt, \"; optimal kernel saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 269)\n",
      "(2, 30)\n",
      "(269,)\n",
      "(30,)\n"
     ]
    }
   ],
   "source": [
    "# Come back to the initial training and sets \n",
    "X_train_final = X_train\n",
    "X_test_final  = X_test\n",
    "\n",
    "# Take the optimal kernel (hyperparameters) to \"train\" the model on the initial training set \n",
    "gp_final      = GaussianProcessRegressor(kernel=opt_gp.kernel_, alpha=0, optimizer=None) #kernel_从cv过程中选择了最优的kernel，The kernel used for prediction. The structure of the kernel is the same as the one passed as parameter but with optimized hyperparameters\n",
    "gp_final.fit(X_train_final, Y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_std    = gp_final.predict(X_train_final,return_std=True)\n",
    "print(np.shape(y_train_std))\n",
    "y_test_std     = gp_final.predict(X_test_final,return_std=True)\n",
    "print(np.shape(y_test_std))\n",
    "y_train = y_train_std[0]\n",
    "print(np.shape(y_train))\n",
    "y_test = y_test_std[0]\n",
    "print(np.shape(y_test))\n",
    "\n",
    "# Error measures\n",
    "rmse_train = np.sqrt(mean_squared_error(Y_train, y_train))\n",
    "rmse_test  = np.sqrt(mean_squared_error(Y_test, y_test))\n",
    "R2_train_  = gp_final.score(X_train_final, Y_train)\n",
    "R2_test_   = gp_final.score(X_test_final, Y_test)\n",
    "\n",
    "# Three optimal hyperparameters can be obtained by the following lines\n",
    "#print (\"k1.k1.constant_value = \" + str(gp_final.kernel_.k1.k1.constant_value))\n",
    "#print (\"k2.noise_level       = \" + str(gp_final.kernel_.k2.noise_level))\n",
    "#print (\"k2.k2.length_scale   = \" + str(gp_final.kernel_.k1.k2.length_scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the prediction\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_size  = 1.0-test_size\n",
    "label_train = 'Train: size = ' + str(train_size) +'; R2 = ' + str('%.3f' % R2_train_) + '; rmse = ' + str(\n",
    "    '%.3f' % rmse_train) #'%.3f' % R2_train_ 小数点后保留三位\n",
    "label_test  = 'Test:  size = ' + str(test_size) + '; R2 = ' + str('%.3f' % R2_test_) + '; rmse = ' + str(\n",
    "    '%.3f' % rmse_test)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.rc('xtick', labelsize=15)\n",
    "plt.rc('ytick', labelsize=15)\n",
    "#设置图片大小，tick大小\n",
    "\n",
    "lim_min = min(min(Y_train), min(Y_test), min(y_train), min(y_test))     \n",
    "lim_max = max(max(Y_train), max(Y_test), max(y_train), max(y_test))\n",
    "lim = [lim_min - (lim_max - lim_min) * 0.1, lim_max + (lim_max - lim_min) * 0.1] \n",
    "plt.xlim(lim)\n",
    "plt.ylim(lim)\n",
    "\n",
    "#plt.text(lim_min + (lim_max - lim_min) * 0.4, lim_min + (lim_max - lim_min) * 0.1, label_train)\n",
    "#plt.text(lim_min + (lim_max - lim_min) * 0.4, lim_min + (lim_max - lim_min) * 0.05, label_test)\n",
    "\n",
    "\n",
    "plt.xlabel(\"Computed sublimation enthalpy (kj/mol)\", size=17)\n",
    "plt.ylabel(\"Predicted sublimation enthalpy (kj/mol)\", size=17)\n",
    "\n",
    "\n",
    "plots_ = list()\n",
    "plot_train = plt.scatter(Y_train, y_train, marker='o', label=\"train\")\n",
    "plots_.append(plot_train)\n",
    "plot_test = plt.scatter(Y_test, y_test, marker='s', label=\"test\")\n",
    "plots_.append(plot_test)\n",
    "\n",
    "#errorbar\n",
    "y_trainerr=y_train_std[1]\n",
    "y_testerr=y_test_std[1]\n",
    "plt.errorbar(Y_train, y_train, yerr=y_trainerr,fmt='o')\n",
    "plt.errorbar(Y_test, y_test, yerr=y_testerr,fmt='o')\n",
    "\n",
    "plt.legend(handles=[plot_train,plot_test],labels=[label_train,label_test],loc='lower right')\n",
    "\n",
    "plt.savefig('./sublimation enthalpy_0.1_1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
